---
sidebar: sidebar 
permalink: trident-use/worker-node-prep.html 
keywords: storage class, manage storage class, storage classes, kubernetes storage classes, worker node, nfs, iscsi, kubernetes clusters, self-healing, healing, nvme, tcp 
summary: 'Tous les nœuds workers du cluster Kubernetes doivent pouvoir monter les volumes provisionnés pour vos pods. Si vous utilisez le pilote ONTAP-nas, ONTAP-nas-économie, ontap-nas-flexgroup pour l"un de vos systèmes back-end, vos nœuds workers ont besoin des outils NFS. Sinon, ils nécessitent les outils iSCSI.' 
---
= Préparez le nœud de travail
:hardbreaks:
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Tous les nœuds workers du cluster Kubernetes doivent pouvoir monter les volumes provisionnés pour vos pods. Pour préparer les nœuds workers, vous devez installer les outils NFS, iSCSI, NVMe/TCP ou FC en fonction de votre sélection de pilotes.



== Choisir les bons outils

Si vous utilisez une combinaison de pilotes, vous devez installer tous les outils requis pour vos pilotes. Les versions récentes de RedHat CoreOS ont les outils installés par défaut.

.Outils NFS
link:https://docs.netapp.com/us-en/trident/trident-use/worker-node-prep.html#nfs-volumes["Installez les outils NFS"] si vous utilisez : `ontap-nas`, `ontap-nas-economy`, `ontap-nas-flexgroup`, `azure-netapp-files`, `gcp-cvs`.

.Outils iSCSI
link:https://docs.netapp.com/us-en/trident/trident-use/worker-node-prep.html#install-the-iscsi-tools["Installez les outils iSCSI"] si vous utilisez : `ontap-san`, `ontap-san-economy`, `solidfire-san`.

.Outils NVMe
link:https://docs.netapp.com/us-en/trident/trident-use/worker-node-prep.html#nvmetcp-volumes["Installez les outils NVMe"] si vous utilisez `ontap-san` Pour le protocole NVMe (Nonvolatile Memory Express) sur TCP (NVMe/TCP).


NOTE: NetApp recommande ONTAP 9.12 ou version ultérieure pour NVMe/TCP.

.Outils SCSI sur FC
Pour plus d'informations sur la configuration des hôtes SAN FC et FC-NVMe, reportez-vous à la sectionlink:https://docs.netapp.com/us-en/ontap/san-config/configure-fc-nvme-hosts-ha-pairs-reference.html["Manières de configurer FC  ; hôtes SAN FC-NVMe"].

link:https://docs.netapp.com/us-en/trident/trident-use/worker-node-prep.html#install-the-fc-tools["Installez les outils FC"] Si vous utilisez `ontap-san` avec sanType `fcp` (SCSI sur FC).

*Points à prendre en compte* : * SCSI sur FC est pris en charge sur les environnements OpenShift et KubeVirt. * SCSI sur FC n'est pas pris en charge sur Docker. * L'auto-rétablissement iSCSI ne s'applique pas au SCSI sur FC.



== Détection des services de nœud

Trident tente de détecter automatiquement si le nœud peut exécuter des services iSCSI ou NFS.


NOTE: La découverte de services de nœuds identifie les services détectés, mais ne garantit pas que les services sont correctement configurés. Inversement, l'absence d'un service découvert ne garantit pas l'échec du montage du volume.

.Révision des événements
Trident crée des événements pour le nœud afin d'identifier les services détectés. Pour passer en revue ces événements, exécutez :

[listing]
----
kubectl get event -A --field-selector involvedObject.name=<Kubernetes node name>
----
.Examiner les services découverts
Trident identifie les services activés pour chaque nœud sur le nœud Trident CR. Pour afficher les services découverts, exécutez :

[listing]
----
tridentctl get node -o wide -n <Trident namespace>
----


== Volumes NFS

Installez les outils NFS à l'aide des commandes de votre système d'exploitation. Assurez-vous que le service NFS est démarré pendant le démarrage.

[role="tabbed-block"]
====
.RHEL 8+
--
[listing]
----
sudo yum install -y nfs-utils
----
--
.Ubuntu
--
[listing]
----
sudo apt-get install -y nfs-common
----
--
====

WARNING: Redémarrez les nœuds workers après l'installation des outils NFS afin d'éviter toute défaillance lors de la connexion des volumes aux conteneurs.



== Volumes iSCSI

Trident peut automatiquement établir une session iSCSI, analyser les LUN et détecter les périphériques à chemins d'accès multiples, les formater et les monter sur un pod.



=== Fonctionnalités d'auto-rétablissement de l'iSCSI

Pour les systèmes ONTAP, Trident exécute l'autorétablissement iSCSI toutes les cinq minutes pour :

. *Identifier* l'état de session iSCSI souhaité et l'état de session iSCSI en cours.
. *Comparer* l'état souhaité à l'état actuel pour identifier les réparations nécessaires. Trident détermine les priorités de réparation et le moment où les réparations doivent être effectuées.
. *Effectuez les réparations* requises pour rétablir l'état de session iSCSI actuel à l'état de session iSCSI souhaité.



NOTE: Les journaux d'activité d'auto-rétablissement se trouvent dans `trident-main` le conteneur sur le pod Demeset respectif. Pour afficher les journaux, vous devez avoir défini `debug` la valeur « true » lors de l'installation de Trident.

Les fonctionnalités d'auto-rétablissement iSCSI de Trident permettent d'éviter :

* Sessions iSCSI obsolètes ou non saines pouvant survenir après un problème de connectivité réseau. Dans le cas d'une session obsolète, Trident attend sept minutes avant de se déconnecter pour rétablir la connexion avec un portail.
+

NOTE: Par exemple, si les secrets CHAP ont tourné sur le contrôleur de stockage et que le réseau perd la connectivité, les anciens secrets CHAP (_obsolète_) pourraient persister. L'auto-rétablissement peut reconnaître ceci et rétablir automatiquement la session pour appliquer les secrets CHAP mis à jour.

* Sessions iSCSI manquantes
* LUN manquantes


*Points à prendre en compte avant de mettre à niveau Trident*

* Si seuls les igroups par nœud (introduits dans 23.04+) sont utilisés, l'auto-rétablissement iSCSI lance des renumérisations SCSI pour tous les périphériques du bus SCSI.
* Si seuls les igroups dont le périmètre est back-end (obsolète à partir de la version 23.04) sont utilisés, l'auto-rétablissement iSCSI lance des renumérisations SCSI pour obtenir les ID de LUN exacts dans le bus SCSI.
* Si une combinaison d'igroups par nœud et d'igroups scoped back-end est utilisée, l'autorétablissement iSCSI lance des renumérisations SCSI pour obtenir des ID de LUN exacts sur le bus SCSI.




=== Installez les outils iSCSI

Installez les outils iSCSI à l'aide des commandes de votre système d'exploitation.

.Avant de commencer
* Chaque nœud du cluster Kubernetes doit avoir un IQN unique. *C'est une condition préalable nécessaire*.
* En cas d'utilisation de RHCOS version 4.5 ou ultérieure ou d'une autre distribution Linux compatible RHEL, avec le `solidfire-san` Pilote et Element OS 12.5 ou version antérieure, assurez-vous que l'algorithme d'authentification CHAP est défini sur MD5 dans `/etc/iscsi/iscsid.conf`. Les algorithmes CHAP sécurisés conformes à la norme FIPS SHA1, SHA-256 et SHA3-256 sont disponibles avec Element 12.7.
+
[listing]
----
sudo sed -i 's/^\(node.session.auth.chap_algs\).*/\1 = MD5/' /etc/iscsi/iscsid.conf
----
* Lorsque vous utilisez des nœuds workers exécutant RHEL/RedHat CoreOS avec iSCSI PVS, spécifiez le `discard` MounOption dans la classe de stockage pour effectuer la réclamation d'espace en ligne. Reportez-vous à la section https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/discarding-unused-blocks_managing-file-systems["Documentation Red Hat"^].


[role="tabbed-block"]
====
.RHEL 8+
--
. Installez les packages système suivants :
+
[listing]
----
sudo yum install -y lsscsi iscsi-initiator-utils device-mapper-multipath
----
. Vérifiez que la version iscsi-initiator-utils est 6.2.0.874-2.el7 ou ultérieure :
+
[listing]
----
rpm -q iscsi-initiator-utils
----
. Activer les chemins d'accès multiples :
+
[listing]
----
sudo mpathconf --enable --with_multipathd y --find_multipaths n
----
+

NOTE: Assurez-vous que `/etc/multipath.conf` contient `find_multipaths no` moins de `defaults`.

. S'assurer que `iscsid` et `multipathd` sont en cours d'exécution :
+
[listing]
----
sudo systemctl enable --now iscsid multipathd
----
. Activer et démarrer `iscsi`:
+
[listing]
----
sudo systemctl enable --now iscsi
----


--
.Ubuntu
--
. Installez les packages système suivants :
+
[listing]
----
sudo apt-get install -y open-iscsi lsscsi sg3-utils multipath-tools scsitools
----
. Vérifiez que la version Open-iscsi est 2.0.874-5ubuntu2.10 ou ultérieure (pour bionique) ou 2.0.874-7.1ubuntu6.1 ou ultérieure (pour focaux) :
+
[listing]
----
dpkg -l open-iscsi
----
. Définir la numérisation sur manuelle :
+
[listing]
----
sudo sed -i 's/^\(node.session.scan\).*/\1 = manual/' /etc/iscsi/iscsid.conf
----
. Activer les chemins d'accès multiples :
+
[listing]
----
sudo tee /etc/multipath.conf <<-EOF
defaults {
    user_friendly_names yes
    find_multipaths no
}
EOF
sudo systemctl enable --now multipath-tools.service
sudo service multipath-tools restart
----
+

NOTE: Assurez-vous que `/etc/multipath.conf` contient `find_multipaths no` moins de `defaults`.

. S'assurer que `open-iscsi` et `multipath-tools` sont activées et en cours d'exécution :
+
[listing]
----
sudo systemctl status multipath-tools
sudo systemctl enable --now open-iscsi.service
sudo systemctl status open-iscsi
----
+

NOTE: Pour Ubuntu 18.04, vous devez découvrir les ports cibles avec `iscsiadm` avant de commencer `open-iscsi` Pour que le démon iSCSI démarre. Vous pouvez également modifier le `iscsi` service à démarrer `iscsid` automatiquement.



--
====


=== Configurez ou désactivez l'auto-rétablissement iSCSI

Vous pouvez configurer les paramètres d'auto-rétablissement iSCSI Trident suivants pour corriger les sessions obsolètes :

* *Intervalle d'auto-rétablissement iSCSI* : détermine la fréquence à laquelle l'auto-rétablissement iSCSI est appelé (par défaut : 5 minutes). Vous pouvez le configurer pour qu'il s'exécute plus fréquemment en définissant un nombre plus petit ou moins fréquemment en définissant un nombre plus grand.


[NOTE]
====
La définition de l'intervalle d'auto-rétablissement iSCSI sur 0 arrête complètement l'auto-rétablissement iSCSI. Nous ne recommandons pas de désactiver l'auto-rétablissement iSCSI. Il ne doit être désactivé que dans certains cas lorsque l'auto-rétablissement iSCSI ne fonctionne pas comme prévu ou à des fins de débogage.

====
* *Délai d'attente d'auto-rétablissement iSCSI* : détermine la durée d'attente de l'auto-rétablissement iSCSI avant de se déconnecter d'une session défectueuse et de tenter de se reconnecter (par défaut : 7 minutes). Vous pouvez le configurer sur un nombre plus grand de sorte que les sessions identifiées comme non saines doivent attendre plus longtemps avant d'être déconnectées, puis une tentative de connexion est faite, ou un nombre plus petit pour se déconnecter et se connecter plus tôt.


[role="tabbed-block"]
====
.Gouvernail
--
Pour configurer ou modifier les paramètres d'auto-rétablissement iSCSI, passez le `iscsiSelfHealingInterval` et `iscsiSelfHealingWaitTime` paramètres lors de l'installation de helm ou de la mise à jour de helm.

L'exemple suivant définit l'intervalle d'auto-rétablissement iSCSI sur 3 minutes et le temps d'attente d'auto-rétablissement sur 6 minutes :

[listing]
----
helm install trident trident-operator-100.2502.0.tgz --set iscsiSelfHealingInterval=3m0s --set iscsiSelfHealingWaitTime=6m0s -n trident
----
--
.tridentctl
--
Pour configurer ou modifier les paramètres d'auto-rétablissement iSCSI, passez le `iscsi-self-healing-interval` et `iscsi-self-healing-wait-time` paramètres lors de l'installation ou de la mise à jour de tridentctl.

L'exemple suivant définit l'intervalle d'auto-rétablissement iSCSI sur 3 minutes et le temps d'attente d'auto-rétablissement sur 6 minutes :

[listing]
----
tridentctl install --iscsi-self-healing-interval=3m0s --iscsi-self-healing-wait-time=6m0s -n trident
----
--
====


== Volumes NVMe/TCP

Installez les outils NVMe à l'aide des commandes correspondant à votre système d'exploitation.

[NOTE]
====
* NVMe requiert RHEL 9 ou version ultérieure.
* Si la version du noyau de votre nœud Kubernetes est trop ancienne ou si le package NVMe n'est pas disponible pour votre version du noyau, vous devrez peut-être mettre à jour la version du noyau de votre nœud avec le package NVMe.


====
[role="tabbed-block"]
====
.RHEL 9
--
[listing]
----
sudo yum install nvme-cli
sudo yum install linux-modules-extra-$(uname -r)
sudo modprobe nvme-tcp
----
--
.Ubuntu
--
[listing]
----
sudo apt install nvme-cli
sudo apt -y install linux-modules-extra-$(uname -r)
sudo modprobe nvme-tcp
----
--
====


=== Vérifiez l'installation

Après l'installation, vérifiez que chaque nœud du cluster Kubernetes dispose d'un NQN unique via la commande :

[listing]
----
cat /etc/nvme/hostnqn
----

WARNING: Trident modifie la `ctrl_device_tmo` valeur pour s'assurer que NVMe ne renonce pas au chemin s'il tombe en panne. Ne modifiez pas ce paramètre.



== Volumes SCSI sur FC

Vous pouvez désormais utiliser le protocole Fibre Channel (FC) avec Trident pour provisionner et gérer les ressources de stockage sur un système ONTAP.



=== Prérequis

Configurez les paramètres réseau et nœud requis pour FC.



==== Paramètres réseau

. Obtenez le WWPN des interfaces cibles. Pour plus d'informations, reportez-vous à la section https://docs.netapp.com/us-en/ontap-cli//network-interface-show.html["interface réseau affiche"^] .
. Procurez-vous le WWPN pour les interfaces sur l'initiateur (hôte).
+
Reportez-vous aux utilitaires correspondants du système d'exploitation hôte.

. Configurer la segmentation sur le commutateur FC à l'aide des WWPN de l'hôte et de la cible.
+
Pour plus d'informations, reportez-vous à la documentation du fournisseur du commutateur Respecive.

+
Pour plus d'informations, reportez-vous à la documentation ONTAP suivante :

+
** https://docs.netapp.com/us-en/ontap/san-config/fibre-channel-fcoe-zoning-concept.html["Présentation de la segmentation Fibre Channel et FCoE"^]
** https://docs.netapp.com/us-en/ontap/san-config/configure-fc-nvme-hosts-ha-pairs-reference.html["Manières de configurer FC  ; hôtes SAN FC-NVMe"^]






=== Installez les outils FC

Installez les outils FC à l'aide des commandes de votre système d'exploitation.

* Lors de l'utilisation de nœuds worker exécutant RHEL/RedHat CoreOS avec FC PVS, spécifiez la `discard` mountOption dans la classe de stockage pour effectuer la récupération d'espace en ligne. Reportez-vous à la https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/8/html/managing_file_systems/discarding-unused-blocks_managing-file-systems["Documentation Red Hat"^].


[role="tabbed-block"]
====
.RHEL 8+
--
. Installez les packages système suivants :
+
[listing]
----
sudo yum install -y lsscsi device-mapper-multipath
----
. Activer les chemins d'accès multiples :
+
[listing]
----
sudo mpathconf --enable --with_multipathd y --find_multipaths n
----
+

NOTE: Assurez-vous que `/etc/multipath.conf` contient `find_multipaths no` moins de `defaults`.

. Assurez-vous que `multipathd` est en cours d'exécution :
+
[listing]
----
sudo systemctl enable --now multipathd
----


--
.Ubuntu
--
. Installez les packages système suivants :
+
[listing]
----
sudo apt-get install -y lsscsi sg3-utils multipath-tools scsitools
----
. Activer les chemins d'accès multiples :
+
[listing]
----
sudo tee /etc/multipath.conf <<-EOF
defaults {
    user_friendly_names yes
    find_multipaths no
}
EOF
sudo systemctl enable --now multipath-tools.service
sudo service multipath-tools restart
----
+

NOTE: Assurez-vous que `/etc/multipath.conf` contient `find_multipaths no` moins de `defaults`.

. Assurez-vous que `multipath-tools` est activé et en cours d'exécution :
+
[listing]
----
sudo systemctl status multipath-tools
----


--
====
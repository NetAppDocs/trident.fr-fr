---
sidebar: sidebar 
permalink: trident-use/monitor-trident.html 
keywords: telemetry, Trident, monitor, metrics, health, volume usage, autosupport 
summary: 'Trident fournit un ensemble de terminaux de metrics Prometheus que vous pouvez utiliser pour contrôler les performances d"Trident.' 
---
= Surveillez Trident
:hardbreaks:
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Trident fournit un ensemble de terminaux de metrics Prometheus que vous pouvez utiliser pour contrôler les performances d'Trident.



== Présentation

Grâce aux mesures fournies par Trident, vous pouvez :

* Surveillez l'état et la configuration de Trident. Vous avez la possibilité d'examiner la réussite des opérations et de savoir si elles peuvent communiquer avec les systèmes back-end comme prévu.
* Examiner les informations d'utilisation du système back-end et comprendre le nombre de volumes provisionnés sur un système back-end, ainsi que la quantité d'espace consommé, etc.
* Conservez un mappage de la quantité de volumes provisionnés sur les systèmes back-end disponibles.
* Suivi des performances. Vous pouvez examiner le temps nécessaire à Trident pour communiquer avec les systèmes back-end et effectuer les opérations.



NOTE: Par défaut, les metrics de Trident sont visibles sur le port cible `8001` au `/metrics` point final. Ces mesures sont *activées par défaut* lors de l'installation de Trident.

.Ce dont vous avez besoin
* Cluster Kubernetes avec Trident installé.
* Instance Prometheus. Il peut s'agir d'un https://github.com/prometheus-operator/prometheus-operator["Déploiement conteneurisé par Prometheus"^] Vous pouvez également utiliser Prometheus en tant que https://prometheus.io/download/["application native"^].




== Étape 1 : définir une cible Prometheus

Vous devez définir une cible Prometheus pour collecter les metrics et obtenir des informations sur les systèmes back-end gérés par Trident, les volumes qu'elle crée, etc.  https://netapp.io/2020/02/20/prometheus-and-trident/["Blog"^]Vous apprendrez ainsi à utiliser Prometheus et Grafana avec Trident pour récupérer des metrics. Découvrez sur ce blog comment exécuter Prometheus en tant qu'opérateur dans votre cluster Kubernetes et comment créer un ServiceMonitor pour obtenir des metrics Trident.



== Étape 2 : créer un ServiceMonitor Prometheus

Pour consommer les metrics Trident, vous devez créer un ServiceMonitor Prometheus qui surveille la `trident-csi` service et écoute sur le `metrics` port. Un exemple de ServiceMonitor se présente comme suit :

[source, yaml]
----
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: trident-sm
  namespace: monitoring
  labels:
    release: prom-operator
spec:
  jobLabel: trident
  selector:
    matchLabels:
      app: controller.csi.trident.netapp.io
  namespaceSelector:
    matchNames:
      - trident
  endpoints:
    - port: metrics
      interval: 15s
----
Cette définition de ServiceMonitor récupère les mesures renvoyées par le `trident-csi` service et recherche spécifiquement le `metrics` point final du service. Par conséquent, Prometheus est désormais configuré pour comprendre les metrics de Trident.

Outre les mesures directement disponibles auprès de Trident, kubelet expose de nombreuses `kubelet_volume_*` mesures via son propre terminal de metrics. Kubelet peut fournir des informations sur les volumes reliés, ainsi que sur les pods et autres opérations internes qu'elle gère. Reportez-vous à la https://kubernetes.io/docs/concepts/cluster-administration/monitoring/["ici"^].



== Étape 3 : interroger les mesures Trident avec PromQL

PromQL est bon pour la création d'expressions qui renvoient des séries chronologiques ou des données tabulaires.

Voici quelques questions PromQL que vous pouvez utiliser :



=== Accédez aux informations sur l'état de santé de Trident

* **Pourcentage de réponses HTTP 2XX de Trident**


[listing]
----
(sum (trident_rest_ops_seconds_total_count{status_code=~"2.."} OR on() vector(0)) / sum (trident_rest_ops_seconds_total_count)) * 100
----
* **Pourcentage de réponses de REPOS de Trident via le code d'état**


[listing]
----
(sum (trident_rest_ops_seconds_total_count) by (status_code)  / scalar (sum (trident_rest_ops_seconds_total_count))) * 100
----
* **Durée moyenne en ms des opérations effectuées par Trident**


[listing]
----
sum by (operation) (trident_operation_duration_milliseconds_sum{success="true"}) / sum by (operation) (trident_operation_duration_milliseconds_count{success="true"})
----


=== Obtenez des informations sur l'utilisation de Trident

* **Taille moyenne du volume**


[listing]
----
trident_volume_allocated_bytes/trident_volume_count
----
* **Espace volume total provisionné par chaque back-end**


[listing]
----
sum (trident_volume_allocated_bytes) by (backend_uuid)
----


=== Utiliser individuellement le volume


NOTE: Cette activation est uniquement possible si les indicateurs kubelet sont également collectés.

* **Pourcentage d'espace utilisé pour chaque volume**


[listing]
----
kubelet_volume_stats_used_bytes / kubelet_volume_stats_capacity_bytes * 100
----


== En savoir plus sur la télémétrie Trident AutoSupport

Par défaut, Trident envoie chaque jour des metrics Prometheus et des informations de base sur le back-end à NetApp.

* Pour empêcher Trident d'envoyer des metrics Prometheus et des informations back-end de base à NetApp, transmettez le `--silence-autosupport` drapeau pendant l'installation de Trident.
* Trident peut également envoyer des journaux de conteneur au support NetApp à la demande via `tridentctl send autosupport`. Vous devrez déclencher Trident pour télécharger ses journaux. Avant de soumettre des journaux, vous devez accepter les fichiers NetApp https://www.netapp.com/company/legal/privacy-policy/["politique de confidentialité"^].
* Sauf mention contraire, Trident récupère les journaux des 24 dernières heures.
* Vous pouvez spécifier la durée de conservation du journal avec l' `--since`indicateur. Par exemple : `tridentctl send autosupport --since=1h`. Ces informations sont collectées et envoyées via un `trident-autosupport` conteneur installé en même temps que Trident. Vous pouvez obtenir l'image du conteneur à l'adresse https://hub.docker.com/r/netapp/trident-autosupport["AutoSupport Trident"^].
* Le AutoSupport Trident ne collecte pas et ne transmet pas d'informations à caractère personnel (PII) ou de données personnelles. Il est fourni avec un https://www.netapp.com/us/media/enduser-license-agreement-worldwide.pdf["CLUF"^] qui ne s'applique pas à l'image du conteneur Trident. Pour en savoir plus sur l'engagement de NetApp en faveur de la sécurité et de la confiance des données https://www.netapp.com/pdf.html?item=/media/14114-enduserlicenseagreementworldwidepdf.pdf["ici"^].


Voici un exemple de charge envoyée par Trident :

[source, yaml]
----
---
items:
  - backendUUID: ff3852e1-18a5-4df4-b2d3-f59f829627ed
    protocol: file
    config:
      version: 1
      storageDriverName: ontap-nas
      debug: false
      debugTraceFlags: null
      disableDelete: false
      serialNumbers:
        - nwkvzfanek_SN
      limitVolumeSize: ""
    state: online
    online: true
----
* Les messages AutoSupport sont envoyés au terminal AutoSupport de NetApp. Si vous utilisez un registre privé pour stocker des images de conteneur, vous pouvez utiliser le `--image-registry` drapeau.
* Vous pouvez également configurer des URL proxy en générant les fichiers YAML d'installation. Pour ce faire, utilisez `tridentctl install --generate-custom-yaml` Pour créer les fichiers YAML et ajouter le `--proxy-url` argument pour le `trident-autosupport` conteneur `trident-deployment.yaml`.




== Désactivez les mesures Trident

Pour désactiver** les mesures signalées, vous devez générer des YAML personnalisées (à l'aide de l' `--generate-custom-yaml` marquer) et modifiez-les pour supprimer le `--metrics` indicateur d'être appelé pour le `trident-main`conteneur.
